{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a TSV of publications with metadata and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). The core python code is also in `publications.py`. Run either from the `markdown_generator` folder after replacing `publications.tsv` with one containing your data.\n",
    "\n",
    "TODO: Make this work with BibTex and other databases of citations, rather than Stuart's non-standard TSV format and citation style.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format\n",
    "\n",
    "The TSV needs to have the following columns: pub_date, title, venue, excerpt, citation, site_url, and paper_url, with a header at the top. \n",
    "\n",
    "- `excerpt` and `paper_url` can be blank, but the others must have values. \n",
    "- `pub_date` must be formatted as YYYY-MM-DD.\n",
    "- `url_slug` will be the descriptive part of the .md file and the permalink URL for the page about the paper. The .md file will be `YYYY-MM-DD-[url_slug].md` and the permalink will be `https://[yourdomain]/publications/YYYY-MM-DD-[url_slug]`\n",
    "\n",
    "This is how the raw file looks (it doesn't look pretty, use a spreadsheet or other program to edit and create)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cat' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!cat publications.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pandas\n",
    "\n",
    "We are using the very handy pandas library for dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import TSV\n",
    "\n",
    "Pandas makes this easy with the read_csv function. We are using a TSV, so we specify the separator as a tab, or `\\t`.\n",
    "\n",
    "I found it important to put this data in a tab-separated values format, because there are a lot of commas in this kind of data and comma-separated values can get messed up. However, you can modify the import statement, as pandas also has read_excel(), read_json(), and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Authors</th>\n",
       "      <th>Title</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Number</th>\n",
       "      <th>Pages</th>\n",
       "      <th>Year</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Schneider, Steffen; Rusak, Evgenia; Eck, Luisa...</td>\n",
       "      <td>Improving robustness against common corruption...</td>\n",
       "      <td>Advances in neural information processing systems</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11539-11551</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rusak, Evgenia; Schott, Lukas; Zimmermann, Rol...</td>\n",
       "      <td>A simple way to make neural networks robust ag...</td>\n",
       "      <td>Computer Vision–ECCV 2020: 16th European Confe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53-69</td>\n",
       "      <td>2020</td>\n",
       "      <td>Springer International Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Michaelis, Claudio; Mitzkus, Benjamin; Geirhos...</td>\n",
       "      <td>Benchmarking robustness in object detection: A...</td>\n",
       "      <td>NeurIPS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1907</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rusak, Evgenia; Schneider, Steffen; Pachitariu...</td>\n",
       "      <td>If your data distribution shifts, use self-lea...</td>\n",
       "      <td>TMLR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Li, Zhe; Ortega Caro, Josue; Rusak, Evgenia; B...</td>\n",
       "      <td>Robust deep learning object recognition models...</td>\n",
       "      <td>PLOS Computational Biology</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>e1010932</td>\n",
       "      <td>2023</td>\n",
       "      <td>Public Library of Science San Francisco, CA USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rusak, Evgenia; Schneider, Steffen; Gehler, Pe...</td>\n",
       "      <td>ImageNet-D: A new challenging robustness datas...</td>\n",
       "      <td>ICML 2022 Shift Happens Workshop</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rusak, Evgenia; Reizinger, Patrik; Zimmermann,...</td>\n",
       "      <td>Content suppresses style: dimensionality colla...</td>\n",
       "      <td>NeurIPS 2022 Workshop: Self-Supervised Learnin...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Authors  \\\n",
       "0  Schneider, Steffen; Rusak, Evgenia; Eck, Luisa...   \n",
       "1  Rusak, Evgenia; Schott, Lukas; Zimmermann, Rol...   \n",
       "2  Michaelis, Claudio; Mitzkus, Benjamin; Geirhos...   \n",
       "3  Rusak, Evgenia; Schneider, Steffen; Pachitariu...   \n",
       "4  Li, Zhe; Ortega Caro, Josue; Rusak, Evgenia; B...   \n",
       "5  Rusak, Evgenia; Schneider, Steffen; Gehler, Pe...   \n",
       "6  Rusak, Evgenia; Reizinger, Patrik; Zimmermann,...   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Improving robustness against common corruption...   \n",
       "1  A simple way to make neural networks robust ag...   \n",
       "2  Benchmarking robustness in object detection: A...   \n",
       "3  If your data distribution shifts, use self-lea...   \n",
       "4  Robust deep learning object recognition models...   \n",
       "5  ImageNet-D: A new challenging robustness datas...   \n",
       "6  Content suppresses style: dimensionality colla...   \n",
       "\n",
       "                                         Publication  Volume  Number  \\\n",
       "0  Advances in neural information processing systems    33.0     NaN   \n",
       "1  Computer Vision–ECCV 2020: 16th European Confe...     NaN     NaN   \n",
       "2                                            NeurIPS     NaN     NaN   \n",
       "3                                               TMLR     NaN     NaN   \n",
       "4                         PLOS Computational Biology    19.0     3.0   \n",
       "5                   ICML 2022 Shift Happens Workshop     NaN     NaN   \n",
       "6  NeurIPS 2022 Workshop: Self-Supervised Learnin...     3.0     NaN   \n",
       "\n",
       "         Pages  Year                                        Publisher  \n",
       "0  11539-11551  2020                                              NaN  \n",
       "1        53-69  2020                Springer International Publishing  \n",
       "2          NaN  1907                                              NaN  \n",
       "3          NaN  2021                                              NaN  \n",
       "4     e1010932  2023  Public Library of Science San Francisco, CA USA  \n",
       "5          NaN  2022                                              NaN  \n",
       "6          NaN  2022                                              NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publications = pd.read_csv(\"citations.tsv\", sep=\"\\t\", header=0)\n",
    "publications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escape special characters\n",
    "\n",
    "YAML is very picky about how it takes a valid string, so we are replacing single and double quotes (and ampersands) with their HTML encoded equivilents. This makes them look not so readable in raw format, but they are parsed and rendered nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\".join(html_escape_table.get(c,c) for c in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Authors        Rusak, Evgenia; Reizinger, Patrik; Zimmermann,...\n",
      "Title          Content suppresses style: dimensionality colla...\n",
      "Publication    NeurIPS 2022 Workshop: Self-Supervised Learnin...\n",
      "Volume                                                         3\n",
      "Number                                                       NaN\n",
      "Pages                                                        NaN\n",
      "Year                                                        2022\n",
      "Publisher                                                    NaN\n",
      "Excerpt                                                 TODOTODO\n",
      "Name: 6, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(row, item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the markdown files\n",
    "\n",
    "This is where the heavy lifting is done. This loops through all the rows in the TSV dataframe, then starts to concatentate a big string (```md```) that contains the markdown for each type. It does the YAML metadata first, then does the description for the individual page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Authors        Schneider, Steffen; Rusak, Evgenia; Eck, Luisa...\n",
      "Title          Improving robustness against common corruption...\n",
      "Publication    Advances in neural information processing systems\n",
      "Volume                                                        33\n",
      "Number                                                       NaN\n",
      "Pages                                                11539-11551\n",
      "Year                                                        2020\n",
      "Publisher                                                    NaN\n",
      "Name: 0, dtype: object\n",
      "---\n",
      "title: \"Improving robustness against common corruptions by covariate shift adaptation\"\n",
      "collection: publications\n",
      "permalink: /publication/2020-Improving_robustness_against_common_corruptions_by_covariate_shift_adaptation\n",
      "excerpt: 'TODOTODO'\n",
      "date: 2020\n",
      "venue: 'Advances in neural information processing systems'\n",
      "---\n",
      "TODOTODO\n",
      "\n",
      "2020-Improving_robustness_against_common_corruptions_by_covariate_shift_adaptation.md\n",
      "1 Authors        Rusak, Evgenia; Schott, Lukas; Zimmermann, Rol...\n",
      "Title          A simple way to make neural networks robust ag...\n",
      "Publication    Computer Vision–ECCV 2020: 16th European Confe...\n",
      "Volume                                                       NaN\n",
      "Number                                                       NaN\n",
      "Pages                                                      53-69\n",
      "Year                                                        2020\n",
      "Publisher                      Springer International Publishing\n",
      "Name: 1, dtype: object\n",
      "---\n",
      "title: \"A simple way to make neural networks robust against diverse image corruptions\"\n",
      "collection: publications\n",
      "permalink: /publication/2020-A_simple_way_to_make_neural_networks_robust_against_diverse_image_corruptions\n",
      "excerpt: 'TODOTODO'\n",
      "date: 2020\n",
      "venue: 'Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part III 16'\n",
      "---\n",
      "TODOTODO\n",
      "\n",
      "2020-A_simple_way_to_make_neural_networks_robust_against_diverse_image_corruptions.md\n",
      "2 Authors        Michaelis, Claudio; Mitzkus, Benjamin; Geirhos...\n",
      "Title          Benchmarking robustness in object detection: A...\n",
      "Publication                                              NeurIPS\n",
      "Volume                                                       NaN\n",
      "Number                                                       NaN\n",
      "Pages                                                        NaN\n",
      "Year                                                        1907\n",
      "Publisher                                                    NaN\n",
      "Name: 2, dtype: object\n",
      "---\n",
      "title: \"Benchmarking robustness in object detection: Autonomous driving when winter is coming. Machine Learning for Autonomous Driving 2019\"\n",
      "collection: publications\n",
      "permalink: /publication/1907-Benchmarking_robustness_in_object_detection:_Autonomous_driving_when_winter_is_coming._Machine_Learning_for_Autonomous_Driving_2019\n",
      "excerpt: 'TODOTODO'\n",
      "date: 1907\n",
      "venue: 'NeurIPS'\n",
      "---\n",
      "TODOTODO\n",
      "\n",
      "1907-Benchmarking_robustness_in_object_detection:_Autonomous_driving_when_winter_is_coming._Machine_Learning_for_Autonomous_Driving_2019.md\n",
      "3 Authors        Rusak, Evgenia; Schneider, Steffen; Pachitariu...\n",
      "Title          If your data distribution shifts, use self-lea...\n",
      "Publication                                                 TMLR\n",
      "Volume                                                       NaN\n",
      "Number                                                       NaN\n",
      "Pages                                                        NaN\n",
      "Year                                                        2021\n",
      "Publisher                                                    NaN\n",
      "Name: 3, dtype: object\n",
      "---\n",
      "title: \"If your data distribution shifts, use self-learning\"\n",
      "collection: publications\n",
      "permalink: /publication/2021-If_your_data_distribution_shifts,_use_self-learning\n",
      "excerpt: 'TODOTODO'\n",
      "date: 2021\n",
      "venue: 'TMLR'\n",
      "---\n",
      "TODOTODO\n",
      "\n",
      "2021-If_your_data_distribution_shifts,_use_self-learning.md\n",
      "4 Authors        Li, Zhe; Ortega Caro, Josue; Rusak, Evgenia; B...\n",
      "Title          Robust deep learning object recognition models...\n",
      "Publication                           PLOS Computational Biology\n",
      "Volume                                                        19\n",
      "Number                                                         3\n",
      "Pages                                                   e1010932\n",
      "Year                                                        2023\n",
      "Publisher        Public Library of Science San Francisco, CA USA\n",
      "Name: 4, dtype: object\n",
      "---\n",
      "title: \"Robust deep learning object recognition models rely on low frequency information in natural images\"\n",
      "collection: publications\n",
      "permalink: /publication/2023-Robust_deep_learning_object_recognition_models_rely_on_low_frequency_information_in_natural_images\n",
      "excerpt: 'TODOTODO'\n",
      "date: 2023\n",
      "venue: 'PLOS Computational Biology'\n",
      "---\n",
      "TODOTODO\n",
      "\n",
      "2023-Robust_deep_learning_object_recognition_models_rely_on_low_frequency_information_in_natural_images.md\n",
      "5 Authors        Rusak, Evgenia; Schneider, Steffen; Gehler, Pe...\n",
      "Title          ImageNet-D: A new challenging robustness datas...\n",
      "Publication                     ICML 2022 Shift Happens Workshop\n",
      "Volume                                                       NaN\n",
      "Number                                                       NaN\n",
      "Pages                                                        NaN\n",
      "Year                                                        2022\n",
      "Publisher                                                    NaN\n",
      "Name: 5, dtype: object\n",
      "---\n",
      "title: \"ImageNet-D: A new challenging robustness dataset inspired by domain adaptation\"\n",
      "collection: publications\n",
      "permalink: /publication/2022-ImageNet-D:_A_new_challenging_robustness_dataset_inspired_by_domain_adaptation\n",
      "excerpt: 'TODOTODO'\n",
      "date: 2022\n",
      "venue: 'ICML 2022 Shift Happens Workshop'\n",
      "---\n",
      "TODOTODO\n",
      "\n",
      "2022-ImageNet-D:_A_new_challenging_robustness_dataset_inspired_by_domain_adaptation.md\n",
      "6 Authors        Rusak, Evgenia; Reizinger, Patrik; Zimmermann,...\n",
      "Title          Content suppresses style: dimensionality colla...\n",
      "Publication    NeurIPS 2022 Workshop: Self-Supervised Learnin...\n",
      "Volume                                                         3\n",
      "Number                                                       NaN\n",
      "Pages                                                        NaN\n",
      "Year                                                        2022\n",
      "Publisher                                                    NaN\n",
      "Name: 6, dtype: object\n",
      "---\n",
      "title: \"Content suppresses style: dimensionality collapse in contrastive learning\"\n",
      "collection: publications\n",
      "permalink: /publication/2022-Content_suppresses_style:_dimensionality_collapse_in_contrastive_learning\n",
      "excerpt: 'TODOTODO'\n",
      "date: 2022\n",
      "venue: 'NeurIPS 2022 Workshop: Self-Supervised Learning-Theory and Practice'\n",
      "---\n",
      "TODOTODO\n",
      "\n",
      "2022-Content_suppresses_style:_dimensionality_collapse_in_contrastive_learning.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for row, item in publications.iterrows():\n",
    "    print(row, item)\n",
    "    \n",
    "    md_filename = str(item[\"Year\"]) + \"-\" + item[\"Title\"][0].replace(\" \", \"_\") + \".md\"\n",
    "    html_filename = str(item[\"Year\"]) + \"-\" + item[\"Title\"][0].replace(\" \", \"_\")\n",
    "    year = str(item[\"Year\"])\n",
    "    \n",
    "    ## YAML variables\n",
    "    \n",
    "    md = \"---\\ntitle: \\\"\"   + item[\"Title\"] + '\"\\n'\n",
    "    \n",
    "    md += \"\"\"collection: publications\"\"\"\n",
    "    \n",
    "    md += \"\"\"\\npermalink: /publication/\"\"\" + html_filename\n",
    "    \n",
    "    item[\"Excerpt\"] = \"TODOTODO\"\n",
    "    \n",
    "    if len(str(item[\"Excerpt\"])) > 5:\n",
    "        md += \"\\nexcerpt: '\" + html_escape(item[\"Excerpt\"]) + \"'\"\n",
    "    \n",
    "    md += \"\\ndate: \" + str(item[\"Year\"])\n",
    "    \n",
    "    md += \"\\nvenue: '\" + html_escape(item[\"Publication\"]) + \"'\"\n",
    "    \n",
    "    #if len(str(item.paper_url)) > 5:\n",
    "    #    md += \"\\npaperurl: '\" + item.paper_url + \"'\"\n",
    "    \n",
    "    #md += \"\\ncitation: '\" + html_escape(item.citation) + \"'\"\n",
    "    \n",
    "    md += \"\\n---\"\n",
    "    \n",
    "    ## Markdown description for individual page\n",
    "        \n",
    "    if len(item[\"Excerpt\"]) > 5:\n",
    "        md += \"\\n\" + html_escape(item[\"Excerpt\"]) + \"\\n\"\n",
    "    \n",
    "    #if len(str(item.paper_url)) > 5:\n",
    "     #   md += \"\\n[Download paper here](\" + item.paper_url + \")\\n\" \n",
    "        \n",
    "    #md += \"\\nRecommended citation: \" + item.citation\n",
    "    \n",
    "    print(md)\n",
    "    print(md_filename)\n",
    "    \n",
    "    md_filename = os.path.basename(md_filename)\n",
    "       \n",
    "    with open(\"../_publications/\" + md_filename, 'w') as f:\n",
    "        f.write(md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files are in the publications directory, one directory below where we're working from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-10-01-paper-title-number-1.md  2015-10-01-paper-title-number-3.md\r\n",
      "2010-10-01-paper-title-number-2.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../_publications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\r\n",
      "title: \"Paper Title Number 1\"\r\n",
      "collection: publications\r\n",
      "permalink: /publication/2009-10-01-paper-title-number-1\r\n",
      "excerpt: 'This paper is about the number 1. The number 2 is left for future work.'\r\n",
      "date: 2009-10-01\r\n",
      "venue: 'Journal 1'\r\n",
      "paperurl: 'http://academicpages.github.io/files/paper1.pdf'\r\n",
      "citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'\r\n",
      "---\r\n",
      "This paper is about the number 1. The number 2 is left for future work.\r\n",
      "\r\n",
      "[Download paper here](http://academicpages.github.io/files/paper1.pdf)\r\n",
      "\r\n",
      "Recommended citation: Your Name, You. (2009). \"Paper Title Number 1.\" <i>Journal 1</i>. 1(1)."
     ]
    }
   ],
   "source": [
    "!cat ../_publications/2009-10-01-paper-title-number-1.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
